# HAR Analysis Agent ü§ñ

Intelligent self-learning agent –¥–ª—è reverse-engineering Perplexity AI API —á–µ—Ä–µ–∑ HAR —Ñ–∞–π–ª—ã.

## üéØ Features

- **üß† Self-Learning:** –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ—Ç –∑–Ω–∞–Ω–∏—è –æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö –≤ SQLite
- **üìä Confidence Scoring:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ endpoint
- **üîÑ Human-in-the-Loop:** Interactive training mode —Å feedback
- **‚ö†Ô∏è Anomaly Detection:** –î–µ—Ç–µ–∫—Ç —Å—Ç—Ä–∞–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ potential issues
- **üóëÔ∏è Deprecation Tracking:** –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —É—Å—Ç–∞—Ä–µ–≤–∞—é—â–∏—Ö API
- **üíæ Persistent Knowledge Base:** SQLite –ë–î –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏
- **üìà Quality Assessment:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞

## üöÄ Quick Start

### Installation

```bash
# –¢—Ä–µ–±—É–µ—Ç—Å—è Python 3.12+
pip install -r requirements.txt  # –¢–æ–ª—å–∫–æ stdlib, –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –Ω–µ—Ç!
```

### Basic Usage

```bash
# 1. –ê–Ω–∞–ª–∏–∑ HAR —Ñ–∞–π–ª–∞ —Å –æ–±—É—á–µ–Ω–∏–µ–º
python har_agent.py analyze your_file.har.json

# 2. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
python har_agent.py train

# 3. –≠–∫—Å–ø–æ—Ä—Ç –≤—ã—É—á–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
python har_agent.py export patterns.json

# 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ knowledge base
python har_agent.py stats
```

## üìä Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         HAR Analysis Agent                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ har_       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Pattern          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ analyzer.py‚îÇ    ‚îÇ Detection        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ         ‚îÇ                    ‚îÇ              ‚îÇ
‚îÇ         ‚ñº                    ‚ñº              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ    Intelligence Engine         ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Confidence scoring          ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Anomaly detection           ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Deprecation tracking        ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ         ‚îÇ                                   ‚îÇ
‚îÇ         ‚ñº                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ    Knowledge Base (SQLite)     ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Patterns                    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Endpoints                   ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Analysis history            ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Human feedback              ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ         ‚îÇ                                   ‚îÇ
‚îÇ         ‚ñº                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ    Output & Learning           ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ JSON reports                ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Pattern export              ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Interactive training        ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîç How It Works

### 1. Pattern Learning

Agent –∏–∑–≤–ª–µ–∫–∞–µ—Ç API endpoints –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∏—Ö –≤ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:

```python
# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π endpoint
/rest/threads/abc123/messages

# –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π pattern
/rest/threads/{id}/messages
```

### 2. Confidence Scoring

```python
Initial: 0.5              # –ù–æ–≤—ã–π endpoint
+0.05 per occurrence      # –ö–∞–∂–¥–æ–µ –ø–æ—è–≤–ª–µ–Ω–∏–µ
+0.10 on correct feedback # Human validation
-0.20 on false positive   # Human correction
Max: 1.0                  # –ü–æ–ª–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
```

### 3. Intelligence Enrichment

–ö–∞–∂–¥—ã–π endpoint –æ–±–æ–≥–∞—â–∞–µ—Ç—Å—è:

```python
@dataclass
class APIEndpointIntel:
    path: str                    # /rest/sse/perplexity_ask
    method: str                  # POST
    category: str                # SSE
    confidence: float            # 0.87
    stability_score: float       # 0.92  ‚Üê —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è
    first_discovered: str        # 2026-01-15T...
    last_seen: str              # 2026-01-23T...
    version_history: List[str]   # [v1, v2]
    deprecation_risk: float      # 0.1   ‚Üê –Ω–∏–∑–∫–∏–π —Ä–∏—Å–∫
    related_endpoints: List[str] # —Å–≤—è–∑–∞–Ω–Ω—ã–µ API
```

### 4. Anomaly Detection

- **unusual_length:** endpoint > 200 —Å–∏–º–≤–æ–ª–æ–≤
- **unresolved_template:** —Å–æ–¥–µ—Ä–∂–∏—Ç `${...}` –∏–ª–∏ `{{...}}`
- **suspicious_params:** —Å—Ç—Ä–∞–Ω–Ω—ã–µ query parameters
- **rate_spike:** —Ä–µ–∑–∫–∏–π —Ä–æ—Å—Ç –≤—ã–∑–æ–≤–æ–≤

## üìö Knowledge Base Schema

### patterns
```sql
CREATE TABLE patterns (
    pattern TEXT UNIQUE,      -- /rest/threads/{id}/...
    category TEXT,            -- REST, SSE, Auth
    confidence REAL,          -- 0.0 - 1.0
    first_seen TEXT,
    last_seen TEXT,
    occurrence_count INTEGER,
    sources TEXT              -- JSON: asset hashes
);
```

### endpoints
```sql
CREATE TABLE endpoints (
    path TEXT UNIQUE,
    method TEXT,
    category TEXT,
    confidence REAL,
    stability_score REAL,
    first_discovered TEXT,
    last_seen TEXT,
    version_history TEXT,     -- JSON
    deprecation_risk REAL,
    related_endpoints TEXT    -- JSON
);
```

### analysis_history
```sql
CREATE TABLE analysis_history (
    har_file TEXT,
    analyzed_at TEXT,
    js_assets_count INTEGER,
    endpoints_found INTEGER,
    new_patterns INTEGER,
    quality_score REAL
);
```

## üéì Interactive Training

```bash
$ python har_agent.py train

üéì Interactive Training Mode
================================================================================

üìç Endpoint: /rest/api-org-management/organizations/{api_org_id}/users
   Current confidence: 0.65

   Feedback (c=correct/f=false/m=missed/s=skip): c
   ‚úì Marked as correct, confidence increased

üìç Endpoint: /rest/sse/handle_tool_user_approval_response
   Current confidence: 0.72

   Feedback (c=correct/f=false/m=missed/s=skip): c
   ‚úì Marked as correct, confidence increased
```

## üìà Example Analysis Report

```json
{
  "summary": {
    "js_assets": 1012,
    "endpoints_found": 410,
    "new_discoveries": 23,
    "anomalies": 3,
    "deprecated_risk": 5,
    "quality_score": 0.92
  },
  "knowledge_stats": {
    "total_patterns": 387,
    "high_confidence_patterns": 312,
    "total_endpoints": 410,
    "high_confidence_endpoints": 354,
    "total_analyses": 15,
    "avg_quality_score": 0.88
  },
  "new_discoveries": [
    {
      "path": "/rest/sse/perplexity_mcp_response",
      "confidence": 0.45,
      "category": "SSE",
      "method": "GET"
    }
  ]
}
```

## üõ†Ô∏è Advanced Usage

### Programmatic API

```python
from har_agent import HARAgent, KnowledgeBase

# Initialize agent
agent = HARAgent(knowledge_db="my_custom.db")

# Analyze without learning
report = agent.analyze_har("file.har.json", learn=False)

# Batch processing
har_files = Path("hars/").glob("*.har.json")
for har_file in har_files:
    agent.analyze_har(str(har_file), learn=True)

# Export patterns
agent.export_learned_patterns("shared_patterns.json")

# Get stats
stats = agent.kb.get_stats()
print(f"Total patterns: {stats['total_patterns']}")

agent.close()
```

### Custom Feedback

```python
# Programmatic feedback
agent.kb.add_feedback(
    endpoint_path="/rest/sse/perplexity_ask",
    feedback_type="correct",
    comment="Verified via manual testing"
)
```

## üîÑ Continuous Improvement

Agent —É–ª—É—á—à–∞–µ—Ç—Å—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º:

1. **Analysis #1:** 410 endpoints, 50% confidence
2. **Analysis #5:** 425 endpoints, 70% confidence (–ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞—Å–ø–æ–∑–Ω–∞—é—Ç—Å—è)
3. **Analysis #10:** 430 endpoints, 85% confidence (–≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)
4. **+Training:** 95%+ confidence –ø–æ—Å–ª–µ human validation

## üìä Quality Metrics

- **Confidence:** —Å—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ –≤—Å–µ–º endpoints
- **Stability Score:** –∫–∞–∫ —á–∞—Å—Ç–æ endpoint –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è
- **Quality Score:** –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ (0.0 - 1.0)
- **Deprecation Risk:** –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å—Ç–∞—Ä–µ–≤–∞–Ω–∏—è API

## üö¶ Next Steps

### Phase 2: Enhanced Intelligence
- [ ] Tree-sitter –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ AST
- [ ] Call graph generation
- [ ] Sourcemap recovery

### Phase 3: ML Integration
- [ ] Clustering similar endpoints
- [ ] Predict new endpoints
- [ ] Automatic category classification

### Phase 4: Real-time
- [ ] Chrome extension –¥–ª—è live HAR capture
- [ ] WebSocket streaming analysis
- [ ] Real-time deprecation alerts

## üìù Related Tools

- `har_analyzer.py` - –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–≥–µ–Ω—Ç–æ–º)
- `tools/` - –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã
- `.copilot-instructions.md` - —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–ª—è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤

## ü§ù Contributing

–°–º. [CONTRIBUTING.md](CONTRIBUTING.md) –¥–ª—è guidelines.

## üìÑ License

MIT License - —Å–º. [LICENSE](LICENSE)

---

**Repository:** [pv-udpv/perplexity-ai-unofficial](https://github.com/pv-udpv/perplexity-ai-unofficial)  
**Issue:** #60  
**Related:** #59 (HAR Analysis Pipeline)
